{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extractions from OpenEO\n",
    "\n",
    "To run the extractions, you need an account in the [Copernicus Data Space Ecosystem (CDSE)](https://dataspace.copernicus.eu/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/WorldCereal/prometheo.git@scaleag_augmentations\n",
    "!pip install git+https://github.com/ScaleAGData/scaleag-vito.git@prometheo-integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "from scaleagdata_vito.openeo.extract_sample_scaleag import (\n",
    "    generate_input_for_extractions,\n",
    "    extract\n",
    ")\n",
    "from scaleagdata_vito.presto.presto_df import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess data correctness before launching the OpenEO jobs \n",
    "You can run some checks on your input file to make sure they are suitable to run the extractions successfully. In particular, it is important to check the validity of the geometries and, ideally, to also have a column containing a unique id for each sample.\n",
    "\n",
    "In case of invalid geometries, you will be provided with both the dataframe with the failing polygons to be fixed and the one with valid geometries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_unique_id(df_path, unique_id):\n",
    "    df = gpd.read_file(df_path)\n",
    "    if df[unique_id].nunique() != df.shape[0]:\n",
    "        logger.info(\"IDs are not unique!\")\n",
    "        return df[df[unique_id].duplicated(keep=False)]\n",
    "    else:\n",
    "        logger.info(\"IDs are unique\")\n",
    "        return None\n",
    "\n",
    "def check_valid_geometry(df):\n",
    "    if isinstance(df, str):\n",
    "        df = gpd.read_file(df)\n",
    "    df_invalid = df[~df.geometry.is_valid]\n",
    "    # Assessing wheather some invalid geometries are present\n",
    "    if len(df_invalid) > 0:\n",
    "        # 1) some invalid geometries are present. Attempt fixing them\n",
    "        df['geometry'] = df.geometry.buffer(0)\n",
    "        df_invalid = df[~df.geometry.is_valid]\n",
    "        df_valid = df[df.geometry.is_valid]\n",
    "        if len(df_invalid) > 0:\n",
    "            # 2) Still some invalid geometries are present. Return them\n",
    "            logger.info(\"Invalid geometries found! Returning invalid geometries\")\n",
    "            return df_invalid, df_valid\n",
    "        else:\n",
    "            # All geometries are now valid. Return fixed dataframe and empty dataframe for invalid geometries\n",
    "            logger.info(\"Fixed some invalid geometries. All geometries are now valid\")\n",
    "            return gpd.GeoDataFrame(), df\n",
    "    else:\n",
    "        # All geometries are valid. Return empty dataframe for invalid geometries\n",
    "        logger.info(\"All geometries are valid\")\n",
    "        return gpd.GeoDataFrame(), df\n",
    "\n",
    "def _save(save_to, original_file_path, df, valid=False):\n",
    "    if valid:\n",
    "        filename = Path(save_to) / f\"{Path(original_file_path).stem}_valid.geojson\"\n",
    "    else:\n",
    "        filename = Path(save_to) / f\"{Path(original_file_path).stem}_invalid.geojson\"\n",
    "    logger.info(f\"Saving invalid geometries to {filename}\")\n",
    "    Path(save_to).mkdir(parents=True, exist_ok=True)\n",
    "    df.to_file(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"/projects/TAP/HEScaleAgData/data/GEOMaize/corrected/.geojson\"\n",
    "invalid_geom, valid_geom = check_valid_geometry(input_file)\n",
    "non_unique_ids = check_unique_id(input_file, unique_id=\"Field_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save files after geometry validity check. If invalid geometries are present, save them to a separate file\n",
    "if len(invalid_geom) > 0:\n",
    "    _save(\n",
    "        save_to=\"/projects/TAP/HEScaleAgData/data/GEOMaize/\",\n",
    "        original_file_path=input_file,\n",
    "        df=invalid_geom,\n",
    "        valid=False,\n",
    "    )\n",
    "\n",
    "# save valid geometries to a separate file\n",
    "_save(\n",
    "    save_to=\"/projects/TAP/HEScaleAgData/data/GEOMaize/\",\n",
    "    original_file_path=input_file,\n",
    "    df=valid_geom,\n",
    "    valid=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide job instructions and start OpenEO extractions\n",
    "\n",
    "1) Indicate the following fields in order to guide the extraction\n",
    "2) In the cell below you will be asked for authentication and be provided with a link. click on the link and login with your CDSE credentials.  \n",
    "3) Once the extraction process will be over, you will find your extracted dataset in the output folder you indicated. You can load it by running `load_dataset` as shown below\n",
    "\n",
    "    ```python\n",
    "    job_params = dict(\n",
    "        output_folder=..., # where to save the extracted dataset\n",
    "        input_df=..., # input georeferenced dataset to run the extractions for \n",
    "        start_date=..., # string indicating from which date to extract data  \n",
    "        end_date=..., # string indicating until which date to extract the data \n",
    "        unique_id_column=..., # name of the column in the input_df containing the unique ID of the samples  \n",
    "        composite_window=..., # \"month\" or \"dekad\" are supported. Default is \"dekad\"\n",
    "    )\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_params = dict(\n",
    "    output_folder=\"/home/giorgia/Private/data/geomaize/Maize_yield_2021/\",\n",
    "    input_df=\"/home/giorgia/Private/data/geomaize/Maize_2021.geojson\",\n",
    "    start_date=\"2021-07-01\",\n",
    "    end_date=\"2021-10-31\",\n",
    "    unique_id_column=\"Field_ID\",\n",
    "    composite_window=\"dekad\",\n",
    ")\n",
    "extract(generate_input_for_extractions(job_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = load_dataset(job_params[\"output_folder\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sadenv(py=3.10)",
   "language": "python",
   "name": "sadenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
