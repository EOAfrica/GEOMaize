{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extractions from OpenEO\n",
    "\n",
    "To run the extractions, you need an account in the [Copernicus Data Space Ecosystem (CDSE)](https://dataspace.copernicus.eu/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/WorldCereal/prometheo.git@scaleag_augmentations\n",
    "!pip install git+https://github.com/ScaleAGData/scaleag-vito.git@prometheo-integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "from scaleagdata_vito.openeo.extract_sample_scaleag import (\n",
    "    generate_input_for_extractions,\n",
    "    extract\n",
    ")\n",
    "from scaleagdata_vito.presto.presto_df import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess data correctness before launching the OpenEO jobs \n",
    "You can run some checks on your input file to make sure they are suitable to run the extractions successfully. In particular, it is important to check the validity of the geometries and, ideally, also to have a column containing a unique id for each sample \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_unique_id(df_path, unique_id):\n",
    "    df = gpd.read_file(df_path)\n",
    "    if df[unique_id].nunique() != df.shape[0]:\n",
    "        logger.info(\"IDs are not unique!\")\n",
    "        return df[df[unique_id].duplicated(keep=False)]\n",
    "    else:\n",
    "        logger.info(\"IDs are unique\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def check_valid_geometry(df_path, save_to=\"\"):\n",
    "    df = gpd.read_file(df_path)\n",
    "    df_valid = df[df.geometry.is_valid]\n",
    "    if len(df_valid) < len(df):\n",
    "        logger.info(\"Invalid geometries found! Returning invalid geometries\")\n",
    "        df_invalid = df[~df.geometry.is_valid]\n",
    "        if save_to:\n",
    "            filename = Path(save_to) / f\"{Path(df_path).stem}_invalid.geojson\"\n",
    "            logger.info(f\"Saving invalid geometries to {filename}\")\n",
    "            Path(save_to).mkdir(parents=True, exist_ok=True)\n",
    "            df_invalid.to_file(filename)\n",
    "        return df_invalid\n",
    "    else:\n",
    "        logger.info(\"All geometries are valid\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"/projects/TAP/HEScaleAgData/data/GEOMaize/Maize_Yield_Polygon_North_Ghana/Polygon_North/Maize_2021_valid.geojson\"\n",
    "invalid_geom = check_valid_geometry(input_file, save_to=\"\")\n",
    "non_unique_ids = check_unique_id(input_file, unique_id=\"Field_ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide job instructions and start OpenEO extractions\n",
    "\n",
    "1) Indicate the following fields in order to guide the extraction\n",
    "2) In the cell below you will be asked for authentication and be provided with a link. click on the link and login with your CDSE credentials.  \n",
    "3) Once the extraction process will be over, you will find your extracted dataset in the output folder you indicated. You can load it by running `load_dataset` as shown below\n",
    "\n",
    "    ```python\n",
    "    job_params = dict(\n",
    "        output_folder=..., # where to save the extracted dataset\n",
    "        input_df=..., # input georeferenced dataset to run the extractions for \n",
    "        start_date=..., # string indicating from which date to extract data  \n",
    "        end_date=..., # string indicating until which date to extract the data \n",
    "        unique_id_column=..., # name of the column in the input_df containing the unique ID of the samples  \n",
    "        composite_window=..., # \"month\" or \"dekad\" are supported. Default is \"dekad\"\n",
    "    )\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_params = dict(\n",
    "    output_folder=\"/home/giorgia/Private/data/geomaize/Maize_yield_2021/\",\n",
    "    input_df=\"/home/giorgia/Private/data/geomaize/Maize_2021.shp\",\n",
    "    start_date=\"2021-07-01\",\n",
    "    end_date=\"2021-10-31\",\n",
    "    unique_id_column=\"Field_ID\",\n",
    "    composite_window=\"dekad\",\n",
    ")\n",
    "extract(generate_input_for_extractions(job_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = load_dataset(job_params[\"output_folder\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sadenv(py=3.10)",
   "language": "python",
   "name": "sadenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
